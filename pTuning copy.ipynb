{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\audiocraft\\models\\musicgen.py:80: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "c:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MusicDataset.__init__() missing 1 required positional argument: 'processor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 72\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m input_ids, audio\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# 데이터셋과 데이터로더 설정\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMusicDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/a/Desktop/MusicGen/musicgen-model/dataset_wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# P-Tuning을 위한 하이퍼파라미터 설정\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: MusicDataset.__init__() missing 1 required positional argument: 'processor'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "\n",
    "from audiocraft.models import MusicGen\n",
    "from personal_musicgen.data.datasets import AudioDataset\n",
    "from personal_musicgen.model_utils import train_step, eval_step\n",
    "\n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "MODEL=\"small\"\n",
    "model = MusicGen.get_pretrained(MODEL)\n",
    "\n",
    "# 데이터셋 준비 (폴더 내의 .wav 및 .json 쌍을 자동으로 찾기)\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, audio_dir, processor, max_length=500):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # 폴더 내 .wav 파일과 동일한 이름을 가진 .json 파일을 찾기\n",
    "        for file in os.listdir(audio_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_file = file\n",
    "                json_file = audio_file.replace(\".wav\", \".json\")\n",
    "                \n",
    "                # .json 파일이 존재하면 data에 추가\n",
    "                if os.path.exists(os.path.join(audio_dir, json_file)):\n",
    "                    self.data.append({\n",
    "                        \"audio_file\": audio_file,\n",
    "                        \"json_file\": json_file\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        description_path = os.path.join(self.audio_dir, item['json_file'])\n",
    "        \n",
    "        # JSON 파일에서 description 읽기\n",
    "        with open(description_path, 'r') as f:\n",
    "            description = json.load(f)['description']\n",
    "        \n",
    "        audio_path = os.path.join(self.audio_dir, item['audio_file'])\n",
    "\n",
    "        # .wav 파일 로딩\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        audio = librosa.resample(audio, sr, 16000)  # 16kHz로 리샘플링\n",
    "\n",
    "        # 텍스트를 모델 입력으로 변환\n",
    "        input_ids = self.processor(description, return_tensors=\"pt\").input_ids.squeeze(0)\n",
    "\n",
    "        # .wav 파일을 텐서로 변환\n",
    "        audio = torch.tensor(audio).float()\n",
    "\n",
    "        return input_ids, audio\n",
    "\n",
    "\n",
    "# 데이터셋과 데이터로더 설정\n",
    "dataset = MusicDataset(audio_dir=\"C:/Users/a/Desktop/MusicGen/musicgen-model/dataset_wav\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# P-Tuning을 위한 하이퍼파라미터 설정\n",
    "learning_rate = 5e-5\n",
    "epochs = 3\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 훈련\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for input_ids, audio in loop:\n",
    "        # device.to() 제거\n",
    "        input_ids = input_ids\n",
    "        audio = audio\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델에 입력값 전달\n",
    "        outputs = model(input_ids=input_ids, labels=input_ids, decoder_input_ids=audio)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "# 모델 저장\n",
    "model_save_path = \"C:/Users/a/Desktop/MusicGen/musicgen-model/musicgen_model\"\n",
    "processor_save_path = \"C:/Users/a/Desktop/MusicGen/musicgen-model/musicgen_processor\"\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "# 모델 평가 (학습 완료 후)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetsNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (1.24.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.1-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.17.1-cp311-cp311-win_amd64.whl.metadata (66 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.11.1-cp311-cp311-win_amd64.whl (440 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-18.0.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 5.0/25.1 MB 33.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.3/25.1 MB 47.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 50.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 36.2 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.17.1-cp311-cp311-win_amd64.whl (90 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.1 aiosignal-1.3.1 attrs-24.2.0 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-18.0.0 xxhash-3.5.0 yarl-1.17.1\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\a\\.cache\\huggingface\\hub\\models--facebook--musicgen-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PromptEncoderConfig.__init__() got an unexpected keyword argument 'prompt_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m MusicGen\u001b[38;5;241m.\u001b[39mget_pretrained(MODEL_NAME)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# P-Tuning 설정\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m \u001b[43mPromptEncoderConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 프롬프트 길이 설정 (길이에 따라 모델 성능에 차이 있음)\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPeftType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPROMPT_TUNING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# P-Tuning 유형 설정\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# P-Tuning 모델 생성\u001b[39;00m\n\u001b[0;32m     25\u001b[0m peft_model \u001b[38;5;241m=\u001b[39m get_peft_model(model, peft_config)\n",
      "\u001b[1;31mTypeError\u001b[0m: PromptEncoderConfig.__init__() got an unexpected keyword argument 'prompt_length'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from peft import get_peft_config, get_peft_model, PeftType, PromptEncoderConfig\n",
    "from audiocraft.models import MusicGen\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import librosa\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# 모델과 tokenizer 설정\n",
    "MODEL_NAME = \"facebook/musicgen-large\"  # 사용할 MusicGen 모델 크기 (small, medium, large 등)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# MusicGen 모델 로드\n",
    "model = MusicGen.get_pretrained(MODEL_NAME)\n",
    "\n",
    "# P-Tuning 설정\n",
    "peft_config = PromptEncoderConfig(\n",
    "    prompt_length=32,  # 프롬프트 길이 설정 (길이에 따라 모델 성능에 차이 있음)\n",
    "    peft_type=PeftType.PROMPT_TUNING,  # P-Tuning 유형 설정\n",
    ")\n",
    "\n",
    "# P-Tuning 모델 생성\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# 데이터셋 준비\n",
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, audio_dir, tokenizer, max_length=500):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # 폴더 내 .wav 파일과 동일한 이름을 가진 .json 파일을 찾기\n",
    "        for file in os.listdir(audio_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_file = file\n",
    "                json_file = audio_file.replace(\".wav\", \".json\")\n",
    "                \n",
    "                if os.path.exists(os.path.join(audio_dir, json_file)):\n",
    "                    self.data.append({\n",
    "                        \"audio_file\": audio_file,\n",
    "                        \"json_file\": json_file\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        description_path = os.path.join(self.audio_dir, item['json_file'])\n",
    "        \n",
    "        # JSON 파일에서 description 읽기\n",
    "        with open(description_path, 'r') as f:\n",
    "            description = json.load(f)['description']\n",
    "        \n",
    "        audio_path = os.path.join(self.audio_dir, item['audio_file'])\n",
    "\n",
    "        # .wav 파일 로딩\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        audio = librosa.resample(audio, sr, 16000)  # 16kHz로 리샘플링\n",
    "\n",
    "        # 텍스트를 모델 입력으로 변환\n",
    "        input_ids = self.tokenizer(description, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_length).input_ids.squeeze(0)\n",
    "\n",
    "        # .wav 파일을 텐서로 변환\n",
    "        audio = torch.tensor(audio).float()\n",
    "\n",
    "        return input_ids, audio\n",
    "\n",
    "\n",
    "# 데이터셋과 데이터로더 설정\n",
    "audio_dir = \"C:/Users/a/Desktop/MusicGen/musicgen-model/dataset_wav\"\n",
    "dataset = MusicDataset(audio_dir, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 5e-5\n",
    "epochs = 3\n",
    "optimizer = AdamW(peft_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 훈련\n",
    "peft_model.train()\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for input_ids, audio in loop:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델에 입력값 전달 (P-Tuning을 통해 프롬프트 학습)\n",
    "        outputs = peft_model(input_ids=input_ids, labels=input_ids, decoder_input_ids=audio)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# 모델 저장\n",
    "model_save_path = \"C:/Users/a/Desktop/MusicGen/musicgen-model/musicgen_model_peft\"\n",
    "peft_model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##다시\n",
    "# \n",
    "# \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, set_peft_model_state_dict, PeftType, PromptEncoderConfig\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "\n",
    "#설정값 지정\n",
    "model_name_or_path = \"facebook/musicgen-small\"\n",
    "task = \"mrpc\"\n",
    "num_epochs = 3\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "\n",
    "# 데이터셋 준비\n",
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, audio_dir, tokenizer, max_length=500):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # 폴더 내 .wav 파일과 동일한 이름을 가진 .json 파일을 찾기\n",
    "        for file in os.listdir(audio_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_file = file\n",
    "                json_file = audio_file.replace(\".wav\", \".json\")\n",
    "                \n",
    "                if os.path.exists(os.path.join(audio_dir, json_file)):\n",
    "                    self.data.append({\n",
    "                        \"audio_file\": audio_file,\n",
    "                        \"json_file\": json_file\n",
    "                    })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        description_path = os.path.join(self.audio_dir, item['json_file'])\n",
    "        \n",
    "        # JSON 파일에서 description 읽기\n",
    "        with open(description_path, 'r') as f:\n",
    "            description = json.load(f)['description']\n",
    "        \n",
    "        audio_path = os.path.join(self.audio_dir, item['audio_file'])\n",
    "\n",
    "        # .wav 파일 로딩\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        audio = librosa.resample(audio, sr, 16000)  # 16kHz로 리샘플링\n",
    "\n",
    "        # 텍스트를 모델 입력으로 변환\n",
    "        input_ids = self.tokenizer(description, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_length).input_ids.squeeze(0)\n",
    "\n",
    "        # .wav 파일을 텐서로 변환\n",
    "        audio = torch.tensor(audio).float()\n",
    "\n",
    "        return input_ids, audio\n",
    "    \n",
    "\n",
    "#평가 metric\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"glue\", task)\n",
    "\n",
    "def compute_metrics(eval_pred) :\n",
    "  preds, labels = eval_pred\n",
    "  preds = np.argmax(preds, axis = 1)\n",
    "  return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "\n",
    "\n",
    "#tokenizer 생성\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "#데이터셋 토큰화\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    outputs = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=None)\n",
    "    return outputs\n",
    "\n",
    "#데이터셋 패딩\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'transformers.models.encodec.modeling_encodec.EncodecModel'> is overwritten by shared audio_encoder config: EncodecConfig {\n",
      "  \"_name_or_path\": \"facebook/encodec_32khz\",\n",
      "  \"architectures\": [\n",
      "    \"EncodecModel\"\n",
      "  ],\n",
      "  \"audio_channels\": 1,\n",
      "  \"chunk_length_s\": null,\n",
      "  \"codebook_dim\": 128,\n",
      "  \"codebook_size\": 2048,\n",
      "  \"compress\": 2,\n",
      "  \"dilation_growth_rate\": 2,\n",
      "  \"hidden_size\": 128,\n",
      "  \"kernel_size\": 7,\n",
      "  \"last_kernel_size\": 7,\n",
      "  \"model_type\": \"encodec\",\n",
      "  \"norm_type\": \"weight_norm\",\n",
      "  \"normalize\": false,\n",
      "  \"num_filters\": 64,\n",
      "  \"num_lstm_layers\": 2,\n",
      "  \"num_residual_layers\": 1,\n",
      "  \"overlap\": null,\n",
      "  \"pad_mode\": \"reflect\",\n",
      "  \"residual_kernel_size\": 3,\n",
      "  \"sampling_rate\": 32000,\n",
      "  \"target_bandwidths\": [\n",
      "    2.2\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"trim_right_ratio\": 1.0,\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    5,\n",
      "    4,\n",
      "    4\n",
      "  ],\n",
      "  \"use_causal_conv\": false,\n",
      "  \"use_conv_shortcut\": false\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.musicgen.modeling_musicgen.MusicgenForCausalLM'> is overwritten by shared decoder config: MusicgenDecoderConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"audio_channels\": 1,\n",
      "  \"bos_token_id\": 2048,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"musicgen_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 4,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 2048,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 2048\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The repository for makeDataset contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/makeDataset.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\datasets\\load.py:122\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[1;34m(trust_remote_code, repo_id)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 122\u001b[0m     signal\u001b[38;5;241m.\u001b[39msignal(\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSIGALRM\u001b[49m, _raise_timeout_error)\n\u001b[0;32m    123\u001b[0m     signal\u001b[38;5;241m.\u001b[39malarm(config\u001b[38;5;241m.\u001b[39mTIME_OUT_REMOTE_CODE)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'signal' has no attribute 'SIGALRM'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m MusicgenForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(modelpath)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 데이터셋 로드\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmakeDataset.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 전역 설정값 지정\u001b[39;00m\n\u001b[0;32m     16\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\datasets\\load.py:2132\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2127\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2128\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2129\u001b[0m )\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2132\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\datasets\\load.py:1853\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1852\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1853\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\datasets\\load.py:1571\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(filename):\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[0;32m   1566\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalDatasetModuleFactoryWithScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1573\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\datasets\\load.py:761\u001b[0m, in \u001b[0;36mLocalDatasetModuleFactoryWithScript.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    754\u001b[0m importable_file_path \u001b[38;5;241m=\u001b[39m _get_importable_file_path(\n\u001b[0;32m    755\u001b[0m     dynamic_modules_path\u001b[38;5;241m=\u001b[39mdynamic_modules_path,\n\u001b[0;32m    756\u001b[0m     module_namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    757\u001b[0m     subdirectory_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhash\u001b[39m,\n\u001b[0;32m    758\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(importable_file_path):\n\u001b[1;32m--> 761\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_trust_remote_code\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n\u001b[0;32m    763\u001b[0m         _create_importable_file(\n\u001b[0;32m    764\u001b[0m             local_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath,\n\u001b[0;32m    765\u001b[0m             local_imports\u001b[38;5;241m=\u001b[39mlocal_imports,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    771\u001b[0m             download_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_mode,\n\u001b[0;32m    772\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\a\\Desktop\\MusicGen\\.conda\\Lib\\site-packages\\datasets\\load.py:138\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[1;34m(trust_remote_code, repo_id)\u001b[0m\n\u001b[0;32m    135\u001b[0m         signal\u001b[38;5;241m.\u001b[39malarm(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;66;03m# OS which does not support signal.SIGALRM\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe repository for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m contains custom code which must be executed to correctly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload the dataset. You can inspect the repository content at https://hf.co/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pass the argument `trust_remote_code=True` to allow custom code to be run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# For the CI which might put the timeout at 0\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     _raise_timeout_error(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: The repository for makeDataset contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/makeDataset.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import MusicgenForConditionalGeneration, AutoTokenizer\n",
    "from peft import get_peft_config, get_peft_model, PeftType, PromptEncoder, PromptEncoderConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "# 사전 학습된 MusicGen 모델\n",
    "modelpath = \"facebook/musicgen-small\"\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(modelpath)\n",
    "\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"makeDataset.py\")\n",
    "\n",
    "# 전역 설정값 지정\n",
    "task = \"mrpc\"\n",
    "num_epochs = 3\n",
    "lr = 1e-3\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "# P-tuning 설정\n",
    "config = PromptEncoderConfig(\n",
    "    peft_type=\"P_TUNING\", \n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    num_virtual_tokens=20,          # 가상 토큰의 수\n",
    "    num_transformer_submodules=1,\n",
    "    num_attention_heads=12,\n",
    "    num_layers=12,\n",
    "    encoder_reparameterization_type=\"MLP\", \n",
    "    encoder_hidden_size=768,\n",
    ")\n",
    "prompt_encoder = PromptEncoder(config)\n",
    "\n",
    "# P-tuning 모델 준비\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 훈련 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"musicgen-ptuning\",             # 모델 저장 위치\n",
    "    per_device_train_batch_size=4,             # 학습 배치 크기\n",
    "    gradient_accumulation_steps=4,             # 기울기 누적 단계\n",
    "    per_device_eval_batch_size=4,              # 평가 배치 크기\n",
    "    warmup_steps=500,                          # 워밍업 단계 수\n",
    "    max_steps=5000,                            # 최대 학습 단계 수\n",
    "    learning_rate=1e-3,                        # 학습률\n",
    "    weight_decay=0.01,                         # 가중치 감쇠\n",
    "    logging_dir=\"./logs\",                      # 로그 저장 위치\n",
    "    logging_steps=100,                         # 로그 기록 간격\n",
    "    evaluation_strategy=\"steps\",               # 평가 전략\n",
    "    eval_steps=500,                           # 평가 간격\n",
    "    save_strategy=\"steps\",                    # 저장 전략\n",
    "    save_steps=500,                          # 저장 간격\n",
    "    load_best_model_at_end=True,             # 최적 모델 로드\n",
    "    metric_for_best_model=\"eval_loss\"        # 최적 모델 선택 기준\n",
    ")\n",
    "\n",
    "#데이터 프로세싱\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)\n",
    "\n",
    "# 데이터 수집기 설정\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # 마스크 언어 모델링 비활성화\n",
    ")\n",
    "\n",
    "\n",
    "# Trainer 인스턴스 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "# 튜닝된 모델 저장\n",
    "model.save_pretrained(\"musicgen-ptuning-tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (4.45.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a\\desktop\\musicgen\\.conda\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 7.6/10.0 MB 39.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 34.8 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.1\n",
      "    Uninstalling transformers-4.45.1:\n",
      "      Successfully uninstalled transformers-4.45.1\n",
      "Successfully installed transformers-4.46.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
